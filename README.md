# Hadoop-HDFS-Hive-Spark
<h2>Abrir:</h2>
https://awsacademy.instructure.com/login/canvas
<br/><br/>
*Este repositorio contiene una colecci√≥n de comandos pr√°cticos y ejemplos para trabajar con Apache Hive, Apache Spark y Hadoop HDFS en entornos distribuidos. Est√° dise√±ado para desarrolladores, cient√≠ficos de datos e ingenieros que trabajen con grandes vol√∫menes de datos y sistemas distribuidos utilizando estas tecnolog√≠as de Big Data. Aqu√≠ encontrar√°s scripts y ejemplos que cubren el procesamiento de datos, consultas SQL sobre Hadoop, y manipulaci√≥n de archivos en sistemas de archivos distribuidos como HDFS.*
<h2 align="center">Historia de Hadoopüìú</h2>
<p>Hadoop fue creado en 2006 por Doug Cutting, inspirado en un elefante de peluche que su hija ten√≠a. Hadoop es una plataforma de software que soporta la computaci√≥n distribuida a gran escala, dise√±ada para manejar grandes vol√∫menes de datos de manera eficiente. Apache Software Foundation es la organizaci√≥n que lo respalda, junto con muchos otros proyectos como SugarCRM y OSCommerce.</p>
<h3>Componentes de Hadoopüîß</h3>

<ul>‚Ä¢	HDFS (Hadoop Distributed File System): Sistema de archivos distribuido que permite el almacenamiento escalable y confiable de grandes vol√∫menes de datos.</ul>
<ul>‚Ä¢	YARN (Yet Another Resource Negotiator): Sistema que gestiona los recursos en cl√∫steres y asigna tareas a trav√©s de diferentes nodos.</ul>
<ul>‚Ä¢	MapReduce: Modelo de programaci√≥n y procesamiento para manejar grandes cantidades de datos de manera distribuida, basado en un algoritmo de clave-valor.</ul>

<h3>Herramientas para manejo de datosüõ†Ô∏è</h3>

<ul>‚Ä¢	Flume: Ingresa datos no estructurados o semiestructurados a Hadoop.</ul>
<ul>‚Ä¢	Sqoop: Transfiere datos estructurados entre bases de datos y Hadoop.</ul>
<ul>‚Ä¢	Kafka & Storm: Herramientas para procesamiento en tiempo real y streaming de datos.</ul>
<ul>‚Ä¢	HBase: Base de datos NoSQL para el almacenamiento de grandes vol√∫menes de datos no estructurados.</ul>

<h3>Procesamiento de datosüíª</h3>

<ul>‚Ä¢	Spark: Motor de procesamiento de datos en memoria que admite m√∫ltiples lenguajes como Scala, R, Python y Java. Ideal para grandes vol√∫menes de datos y an√°lisis en tiempo real.</ul>
<ul>‚Ä¢	Solr & Lucene: Tecnolog√≠as para b√∫squeda e indexaci√≥n de grandes cantidades de datos.</ul>
<ul>‚Ä¢	Hive y Drill: Hive es un sistema de gesti√≥n de datos para trabajar con datos estructurados en Hadoop utilizando HQL (Hive Query Language). Drill permite realizar consultas distribuidas y r√°pidas sobre grandes vol√∫menes de datos.</ul>
<ul>‚Ä¢	Pig: Lenguaje de alto nivel para la creaci√≥n de flujos de datos y procesamiento de grandes conjuntos de datos en Hadoop.</ul>
<ul>‚Ä¢	Oozie: Sistema de planificaci√≥n de flujos de trabajo que permite programar y ejecutar tareas en Hadoop de manera similar a los crons en Linux.</ul>
<ul>‚Ä¢	Zookeeper & Ambari: Herramientas para la gesti√≥n y coordinaci√≥n de cl√∫steres de Hadoop.</ul>

<h3>T√©cnicas avanzadasüîç</h3>

<ul>‚Ä¢	Miner√≠a de datos: Proceso de analizar grandes vol√∫menes de datos para descubrir patrones y relaciones ocultas.</ul>
<ul>‚Ä¢	Machine Learning: T√©cnica de aprendizaje autom√°tico que permite construir modelos predictivos basados en grandes conjuntos de datos.</ul>
<ul>‚Ä¢	Big Data: Referencia al conjunto de tecnolog√≠as y m√©todos que permiten almacenar, procesar y analizar grandes vol√∫menes de datos. El Big Data combina miner√≠a de datos y machine learning para obtener informaci√≥n √∫til y accionable.</ul>
<h3>Cloud y Big Data‚òÅÔ∏è</h3>
<ul>‚Ä¢	Cloud Storage: Servicio de almacenamiento en la nube que permite gestionar y almacenar grandes cantidades de datos de manera eficiente.</ul>
<ul>‚Ä¢	Cloud Pub/Sub: Servicio de mensajer√≠a as√≠ncrona en tiempo real para la comunicaci√≥n entre aplicaciones.</ul>
<ul>‚Ä¢	GSP Big Data: Google Skill Boost ofrece formaci√≥n en herramientas y conceptos de Big Data a trav√©s de la plataforma de Google Cloud (ver video en Google Cloud sobre este tema).</ul>
<ul>‚Ä¢	Dataproc: Servicio para ejecutar cl√∫steres de Hadoop y Spark, facilitando el procesamiento de big data.</ul>
<ul>‚Ä¢	Dataprep: Herramienta visual para limpiar y preparar datos sin escribir c√≥digo, lista para an√°lisis.</ul>
<ul>‚Ä¢	Dataflow: Procesamiento de datos en tiempo real para ETL y an√°lisis, basado en Apache Beam.</ul>
<ul>‚Ä¢	Bigquery: Data warehouse escalable para an√°lisis de grandes vol√∫menes de datos mediante SQL.</ul>

<p>HDFS( (Hadoop Distributed File System), es un sistema de archivos distribuido dise√±ado para almacenar y gestionar grandes vol√∫menes de datos en entornos de cl√∫steres de computadoras, es software de c√≥digo abierto, desarrollado por Apache</p>

ip de uso 172.31
